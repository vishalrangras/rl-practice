{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cart and Pole Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization without Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, time\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "for _ in range(150):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample())\n",
    "    time.sleep(0.01)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math, random, matplotlib, torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython: from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, img_height, img_width):\n",
    "        super.__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=img_height*img_width*3, out_features=24)\n",
    "        self.fc2 = nn.Linear(in_features=24, out_features=32)\n",
    "        self.out = nn.Linear(in_features=32, out_features=2)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = t.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience(state=9, action=3, next_state=4, reward=8)\n"
     ]
    }
   ],
   "source": [
    "Experience = namedtuple('Experience',('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "# Example of Experience Class\n",
    "e = Experience(9, 3, 4, 8)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "    \n",
    "    def push(self, experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.push_count % self.capacity] = experience\n",
    "        self.push_count += 1\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def can_provide_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon Greedy Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyStrategy():\n",
    "    def __init__(self, start, end, decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay = decay\n",
    "        \n",
    "    def get_exploration_rate(self, current_step):\n",
    "        return self.end + (self.start - self.end) *\\\n",
    "            math.exp(-1 * current_step * self.decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, strategy, num_actions, device):\n",
    "        self.current_step = 0\n",
    "        self.strategy = strategy\n",
    "        self.num_actions = num_actions\n",
    "        self.device = device\n",
    "        \n",
    "    def select_action(self, state, policy_net):\n",
    "        rate = self.strategy.get_exploration_rate(self.current_step)\n",
    "        self.current_step += 1\n",
    "        \n",
    "        if rate > random.random():\n",
    "            action = random.randrange(self.num_actions) # Explore\n",
    "            return torch.tensor([action]).to(device)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return policy_net(state).argmax(dim=1).to(device) # Exploit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleEnvManager():\n",
    "    \n",
    "    def __init(self, device):\n",
    "        self.device = device\n",
    "        self.env = gym.make('CartPole-v0').unwrapped\n",
    "        self.env.resent()\n",
    "        self.current_screen = None\n",
    "        self.done = False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "        \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "        \n",
    "    def render(self, mode='human'):\n",
    "        return self.env.render(mode)\n",
    "    \n",
    "    def num_actions_available(self):\n",
    "        return self.env.action_space.n\n",
    "    \n",
    "    def take_action(self, action):\n",
    "        _, reward, self.done, _ = self.env.step(action.item())\n",
    "        return torch.tensor([reward], device = self.device)\n",
    "    \n",
    "    def just_starting(self):\n",
    "        return self.current_screen is None\n",
    "    \n",
    "    def get_state(self):\n",
    "        if self.just_starting() or self.done:\n",
    "            self.current_screen = self.get_processed_screen()\n",
    "            black_screen = torch.zeros_like(self.current_screen)\n",
    "            return black_screen\n",
    "        else:\n",
    "            s1 = self.current_screen\n",
    "            s2 = self.get_processed_screen()\n",
    "            self.current_screen = s1\n",
    "            return s2 - s1\n",
    "        \n",
    "    def get_screen_height(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[2]\n",
    "    \n",
    "    def get_screen_width(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[3]\n",
    "    \n",
    "    def get_processed_screen(self):\n",
    "        screen = self.render('rgb_array').transponse((2, 0, 1))   #Pytorch Expects this order\n",
    "        screen = self.crop_screen(screen)\n",
    "        return self.transform_screen_data(screen)\n",
    "    \n",
    "    def crop_screen(self, screen):\n",
    "        screen_height = screen.shape[1]\n",
    "        \n",
    "        #Strip off top and bottom\n",
    "        top = int(screen_height * 0.4)\n",
    "        bottom = int(screen_height * 0.8)\n",
    "        screen = screen[:, top:bottom, :]\n",
    "        return screen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
